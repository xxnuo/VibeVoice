#!/usr/bin/env python3
"""
VibeVoice å¤šGPUåŠŸèƒ½æµ‹è¯•è„šæœ¬
"""

import torch
import time
import sys
import os

def test_gpu_availability():
    """æµ‹è¯•GPUå¯ç”¨æ€§"""
    print("ğŸ” æ£€æµ‹GPUç¯å¢ƒ...")
    
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨")
        return False
    
    gpu_count = torch.cuda.device_count()
    print(f"âœ… æ£€æµ‹åˆ° {gpu_count} ä¸ªGPU")
    
    for i in range(gpu_count):
        try:
            device_name = torch.cuda.get_device_name(i)
            memory_total = torch.cuda.get_device_properties(i).total_memory / (1024**3)
            print(f"   GPU {i}: {device_name} ({memory_total:.1f}GB)")
            
            # æµ‹è¯•GPUå¯ç”¨æ€§
            with torch.cuda.device(i):
                test_tensor = torch.tensor([1.0], device=f'cuda:{i}')
                result = test_tensor * 2
                del test_tensor, result
                torch.cuda.empty_cache()
                
        except Exception as e:
            print(f"   âŒ GPU {i} æµ‹è¯•å¤±è´¥: {e}")
            
    return gpu_count > 1

def test_multi_gpu_demo():
    """æµ‹è¯•å¤šGPUæ¼”ç¤ºè„šæœ¬"""
    print("\nğŸ§ª æµ‹è¯•å¤šGPUæ¼”ç¤ºè„šæœ¬...")
    
    # æ£€æŸ¥æ¼”ç¤ºè„šæœ¬æ˜¯å¦å­˜åœ¨
    demo_path = "gradio_demo.py"
    if not os.path.exists(demo_path):
        print(f"âŒ æ¼”ç¤ºè„šæœ¬ä¸å­˜åœ¨: {demo_path}")
        return False
    
    # å°è¯•å¯¼å…¥ä¸»è¦ç»„ä»¶
    try:
        sys.path.insert(0, os.path.dirname(demo_path))
        from gradio_demo import GPUManager, GPUStatus
        print("âœ… æˆåŠŸå¯¼å…¥GPUManagerå’ŒGPUStatus")
        
        # æµ‹è¯•GPUStatusæ•°æ®ç»“æ„
        status = GPUStatus(
            gpu_id=0,
            device_name="Test GPU",
            memory_used=10.0,
            memory_total=40.0,
            utilization=50.0,
            queue_length=2,
            is_available=True,
            last_updated=time.time()
        )
        
        print(f"âœ… GPUStatusæµ‹è¯•é€šè¿‡: å†…å­˜ä½¿ç”¨ç‡ {status.memory_usage_percent:.1f}%")
        
        return True
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_gpu_manager_initialization():
    """æµ‹è¯•GPUManageråˆå§‹åŒ–ï¼ˆéœ€è¦æ¨¡å‹è·¯å¾„ï¼‰"""
    print("\nğŸ”§ æµ‹è¯•GPUManageråˆå§‹åŒ–...")
    
    # è¿™é‡Œéœ€è¦å®é™…çš„æ¨¡å‹è·¯å¾„ï¼Œæ‰€ä»¥åªåšåŸºæœ¬æ£€æŸ¥
    try:
        from gradio_demo import GPUManager
        print("âœ… GPUManagerç±»å¯ä»¥æ­£å¸¸å¯¼å…¥")
        print("ğŸ’¡ æ³¨æ„: å®Œæ•´æµ‹è¯•éœ€è¦æœ‰æ•ˆçš„æ¨¡å‹è·¯å¾„")
        return True
    except Exception as e:
        print(f"âŒ GPUManagerå¯¼å…¥å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ™ï¸ VibeVoice å¤šGPUåŠŸèƒ½æµ‹è¯•\n")
    
    tests = [
        ("GPUå¯ç”¨æ€§", test_gpu_availability),
        ("æ¼”ç¤ºè„šæœ¬å¯¼å…¥", test_multi_gpu_demo),
        ("GPUManageråˆå§‹åŒ–", test_gpu_manager_initialization),
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\n{'='*50}")
        print(f"æµ‹è¯•: {test_name}")
        print('='*50)
        
        try:
            if test_func():
                print(f"âœ… {test_name} - é€šè¿‡")
                passed += 1
            else:
                print(f"âŒ {test_name} - å¤±è´¥")
        except Exception as e:
            print(f"âŒ {test_name} - å¼‚å¸¸: {e}")
    
    print(f"\n{'='*50}")
    print(f"æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    print('='*50)
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¤šGPUåŠŸèƒ½å·²å°±ç»ªã€‚")
        print("\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
        print("   python gradio_demo.py --model_path /path/to/model")
        print("   python gradio_demo.py --model_path /path/to/model --gpus '0,1'")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®ã€‚")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)